<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Setting up Hadoop 2.6 on Mac OS X Yosemite</title>
  <meta name="keywords" content="Hadoop, Yosemite, Mac, OS">
  <meta name="description" content="Setting up Hadoop 2.6 on Mac OS X Yosemite">
  <meta name="author" content="Yaonan Zhong">
  <meta name="viewport" content="width=device-width, initial-scale=1.0"> 
  <link rel="stylesheet" type="text/css" href="/css/style.css">
  <link href='http://fonts.googleapis.com/css?family=Roberto' rel='stylesheet'>
  <link href="http://maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css" rel="stylesheet">
  <link rel="stylesheet" type="text/css" href="/css/prism-bash.css">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge">
</head>

<body>
  <header>
    <img src="/images/myself.jpg" alt="Yaonan Zhong">
    <h1><a href="/">Yaonan Zhong</a></h1>
    <nav>
      <a href="/">
        <span class="fa-stack">
          <i class="fa fa-square-o fa-stack-2x fa-fw"></i>
          <i class="fa fa-home fa-stack-1x fa-fw"></i>
        </span>
        <span class="nav-item">Home</span>
      </a>

      <a href="#">
        <span class="fa-stack">
          <i class="fa fa-square-o fa-stack-2x fa-fw"></i>
          <i class="fa fa-user fa-stack-1x fa-fw"></i>
        </span>
        <span class="nav-item">About</span>
      </a>

      <a href="#">
        <span class="fa-stack">
          <i class="fa fa-square-o fa-stack-2x fa-fw"></i>
          <i class="fa fa-futbol-o fa-stack-1x fa-fw"></i>
        </span>
        <span class="nav-item">Life</span>
      </a>

      <a href="https://www.linkedin.com/in/yaonanzhong" target="_blank">
        <span class="fa-stack">
          <i class="fa fa-square-o fa-stack-2x fa-fw"></i>
          <i class="fa fa-linkedin fa-stack-1x fa-fw"></i>
        </span>
        <span class="nav-item">Linkedin</span>
      </a>
      <a href="https://www.github.com/zhongyn" target="_blank">
        <span class="fa-stack">
          <i class="fa fa-square-o fa-stack-2x fa-fw"></i>
          <i class="fa fa-github-alt fa-stack-1x fa-fw"></i>
        </span>
        <span class="nav-item">Github</span>
      </a>
    </nav>  
  </header>
  <article class="language-bash"> 
    <h1>Setting up Hadoop 2.6 on Mac OS X Yosemite</h1>

    <p>After comparing different guides on the internet, I ended up my own version base on the Hadoop official guide with manual download. If you prefer Homebrew, <a href="http://getblueshift.com/blog/setting-up-hadoop-2-4-and-pig-0-12-on-osx-locally/" target="_blank">this one would be your best choice.</a> Actually there is no difference in the configuration of these two methods except the file directories. Here I extend the official guide by more details in case you need it.</p>

    <h2>1. Required software</h2>
    <section>
    <h3>1) Java</h3>
    <p>Run the following command in a terminal:</p>
    <pre><code>$ java -version</code></pre>
    <p>If Java is already installed, you can see a similar result like:</p>
    <pre><code>$ java -version
java version "1.8.0_25"
Java(TM) SE Runtime Environment (build 1.8.0_25-b17)
Java HotSpot(TM) 64-Bit Server VM (build 25.25-b02, mixed mode)</code></pre>

    <p>If not, the terminal will prompt you for installation or you can <a href="http://www.oracle.com/technetwork/java/javase/downloads/index.html" target="_blank">download Java JDK here.</a>
    </p>
    <h3>2) SSH</h3>
    <p>First enable <strong>Remote Login</strong> in <strong>System Preference -> Sharing</strong>.</p>
    <p>Now check that you can ssh to the localhost without a passphrase:</p>

    <pre><code>$ ssh localhost</code></pre>
    <p>If you cannot ssh to localhost without a passphrase, execute the following commands:</p>
    <pre><code>$ ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa
$ cat ~/.ssh/id_dsa.pub >> ~/.ssh/authorized_keys</code></pre>
    </pre>
    </section>
    <h2>2. Get a Hadoop distribution</h2>
    <section>
    <p>You can download it from <a href="http://www.apache.org/dyn/closer.cgi/hadoop/common/" target="_blank">Apache Download Mirror.</a></p>
    </section>
    <h2>3. Prepare to start the Hadoop cluster</h2>
    <section>
    <p>1) Unpack the downloaded Hadoop distribution.</p>

    <p>2) Run the following command to figure out where is your Java home directory:
    <pre><code>$ /usr/libexec/java_home</code></pre>

    <p>You can see a result like:</p>
    <pre><code>$ /usr/libexec/java_home
/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home</code></pre>

    <p>3) In the distribution,  edit the file <strong>etc/hadoop/hadoop-env.sh</strong> to define some parameters as follows:
    <pre><code># set to the root of your Java installation
export JAVA_HOME={your java home directory}
# set to the root of your Hadoop installation
export HADOOP_PREFIX={your hadoop distribution directory}</code></pre>
    <p>Try the following command:</p>

    <pre><code>$ cd {your hadoop distribution directory}
$ bin/hadoop</code></pre>
    <p>This will display the usage documentation for the hadoop script.</p>

    <p>Now you are ready to start your Hadoop cluster in one of the three supported modes:<p>
    <ul>
    <li>Standalone mode</li>
    <li>Pseudo-distributed mode</li>
    <li>fully-distributed mode</li>
  </ul>
    <p>We will go through pseudo-distributed mode and run a MapReduce job on YARN here. In this mode, Hadoop runs on a single node and each Hadoop daemon runs in a separate Java process.<p>
    </section>
     
    <h2>4. Configuration</h2>
    <section>
<p>Edit following config files in your Hadoop directory </p>
    
    <p><strong>1) etc/hadoop/core-site.xml:</strong></p>

    <pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;fs.defaultFS&lt;/name&gt;
        &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;</code></pre>
    
    <p><strong>2) etc/hadoop/hdfs-site.xml:</strong></p>

    <pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.replication&lt;/name&gt;
        &lt;value&gt;1&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;</pre></code>


    <p><strong>3) etc/hadoop/mapred-site.xml:</strong></p>

    <pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
        &lt;value&gt;yarn&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;</pre></code>

    <p><strong>4) etc/hadoop/yarn-site.xml:</strong></p>

    <pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;</pre></code>
  </section>
    <h2>5. Execution</h2>
    $ cd <your hadoop distribution directory>
    Format the filesystem:
    $ bin/hdfs namenode -format
    Start NameNode daemon and DataNode daemon:
    $ sbin/start-dfs.sh
    Browse the web interface for the NameNode; by default it is available at:
    NameNode - http://localhost:50070/
    Make the HDFS directories required to execute MapReduce jobs:
    $ bin/hdfs dfs -mkdir /user
    $ bin/hdfs dfs -mkdir /user/<username> #make sure you add correct username here5
    5. Start ResourceManager daemon and NodeManager daemon:
    $ sbin/start-yarn.sh

    Copy the input files into the distributed filesystem:
    $ bin/hdfs dfs -put etc/hadoop input
    Run some of the examples provided:
    $ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar grep input output 'dfs[a-z.]+'
    Examine the output files:
    Copy the output files from the distributed filesystem to the local filesystem and examine them:

    $ bin/hdfs dfs -get output output
    $ cat output/*
    or

    View the output files on the distributed filesystem:

    $ bin/hdfs dfs -cat output/*
    When you're done, stop the daemons with:
    $ sbin/stop-yarn.sh
    $ sbin/stop-dfs.sh
    </section>
  </article>
  // <script src="/javascript/prism-bash.js"></script>
</body>

</html>
